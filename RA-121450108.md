---
jupyter:
  colab:
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.9.13
  nbformat: 4
  nbformat_minor: 0
---

::: {.cell .markdown id="_buVGGI1eUp3"}
## TUGAS TEKNOLOGI BASIS DATA

### VANESSA OLIVIA ROSE

### 121450108 (RA) {#121450108-ra}
:::

::: {.cell .markdown id="EfjZyhuffoxC"}
Pada tahap ini, kita mendefiniskan fungsi `unpickle()` setelah itu, dua
list kosong diciptakan: `images` untuk menyimpan gambar dan `labels`
untuk label setiap gambar. Lalu pada setiap file `unpickle()` untuk
mendapatkan gambar dan labelnya.
:::

::: {.cell .code execution_count="1" colab="{\"base_uri\":\"https://localhost:8080/\"}" id="xnaMQB0weUp7" outputId="41ea8fe8-13ba-4997-a651-f2678dd16bf7"}
``` python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/Vanessa Olivia/Downloads/cifar-10-python/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

::: {.output .stream .stdout}
    Loaded CIFAR-10 training set:
     - np.shape(images)     (0,)
     - np.shape(labels)     (0,)
:::
:::

::: {.cell .markdown id="Dkd1nGN9eUp9"}
objek-objek dibawah, dapat mudah melakukan operasi-operasi terkait file
dan direktori seperti manipulasi file, pembuatan direktori baru, atau
pemeriksaan keberadaan file.
:::

::: {.cell .code execution_count="2" id="eQBAUMWKeUp9"}
``` python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
:::

::: {.cell .markdown id="ZA5oksk_eUp-"}
sintaks dibawah ini secara efisien membuat tiga direktori yang
diperlukan untuk penyimpanan data dalam suatu proyek.
:::

::: {.cell .code execution_count="3" id="oI4tO5T-eUp_"}
``` python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
:::

::: {.cell .markdown id="tpfolnrueUqA"}
dibawah merupakan fungsi untuk menyimpan gambar dan label ke direktori
menggunakan objek `path`
:::

::: {.cell .code execution_count="4" id="i3Q32XkveUqA"}
``` python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
:::

::: {.cell .markdown id="lJ0H_RkfeUqB"}
Kelas `CIFAR_Image` berfungsi untuk merepresentasikan gambar dari
dataset CIFAR. selain itu, kelas ini dapat menginisialisasi objek dengan
atribut-atribut seperti jumlah channel (misalnya RGB memiliki tiga
channel), dimensi gambar, dan isi gambar yang dikonversi menjadi bytes.
Selain itu, kelas ini juga menyimpan label dari gambar tersebut.
Metode `get_image` digunakan untuk mengembalikan gambar dalam bentuk
array numpy sesuai dengan dimensi dan channel yang telah disimpan
sebelumnya. Kelas ini dapat dengan mudah mengelola dan memproses
gambar-gambar dari dataset CIFAR dalam format yang sesuai untuk analisis
lebih lanjut.
:::

::: {.cell .code execution_count="5" id="jUGUfKKveUqB"}
``` python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
:::

::: {.cell .markdown id="wk9sETIDeUqC"}
Fungsi dibawah untuk menyimpan gambar ke dalam basis data LMDB. Pertama,
kita menghitung ukuran basis data LMDB berdasarkan ukuran gambar yang
akan disimpan. Kemudian, kita buat lingkungan LMDB baru dengan ukuran
tersebut. Selanjutnya, kita mulai transaksi tulis di lingkungan LMDB dan
menyimpan gambar beserta labelnya dalam bentuk objek `CIFAR_Image`, yang
kita serialize menggunakan modul `pickle`. Setelah semua data
dimasukkan, transaksi ditutup dan lingkungan LMDB ditutup. Dengan fungsi
ini, Anda dapat menyimpan gambar-gambar dari dataset CIFAR ke dalam
basis data LMDB untuk digunakan nanti.
:::

::: {.cell .code execution_count="8" id="VdGFM0XbeUqC"}
``` python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```
:::

::: {.cell .markdown id="6GMMFyW1eUqC"}
Selanjutnya, Fungsi ini digunakan untuk menyimpan gambar dan
metadata-nya ke dalam file HDF5. Pertama, kita membuat file HDF5 baru
dengan nama sesuai dengan ID gambar. Selanjutnya, kita buat dataset
untuk gambar dan metadata di dalam file tersebut menggunakan
`create_dataset`. Dataset untuk gambar dinamai \"image\" dengan tipe
data unsigned 8-bit integer big endian. Dataset untuk metadata dinamai
\"meta\" dengan tipe data yang sama seperti gambar. Setelah dataset
dibuat dan diisi dengan data, kita tutup file HDF5. Dengan menggunakan
fungsi ini, Anda dapat dengan mudah menyimpan gambar beserta
metadata-nya ke dalam file HDF5 untuk digunakan dalam analisis data
lebih lanjut.
:::

::: {.cell .code execution_count="9" id="8XS_tiBYeUqD"}
``` python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
:::

::: {.cell .markdown id="8hmKGPsFeUqD"}
Fungsi dibawah menggunakan `_store_single_funcs` berisi tiga fungsi:
`store_single_disk`, `store_single_lmdb`, dan `store_single_hdf5`, yang
masing-masing terkait dengan metode penyimpanan data yang berbeda
(`disk`, `lmdb`, dan `hdf5`). Ini memungkinkan pengguna untuk memilih
metode penyimpanan yang sesuai dengan kebutuhan aplikasi dengan
memanggil fungsi yang sesuai dengan kunci yang diinginkan. Misalnya,
`'disk'` untuk penyimpanan di disk, `'lmdb'` untuk penyimpanan di LMDB,
dan `'hdf5'` untuk penyimpanan di HDF5. Dengan cara ini, fleksibilitas
dalam memilih cara penyimpanan data dapat diterapkan dengan mudah dalam
program.
:::

::: {.cell .code id="XF7cRScCeUqD"}
``` python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
:::

::: {.cell .markdown id="uVE2Pky4eUqE"}
Dari hasil dibawah, dapat disimpulkan bahwa metode lmdb adalah yang
paling cepat dalam hal waktu penyimpanan data, diikuti oleh metode hdf5,
dan metode disk merupakan yang memakan waktu paling lama di antara
ketiganya. Informasi ini berguna untuk mengevaluasi performa relatif
dari berbagai metode penyimpanan data dan memilih yang paling sesuai
berdasarkan kebutuhan aplikasi.
:::

::: {.cell .code id="khCxQfF4eUqE" outputId="4c1c3c1b-8cd8-421d-a38d-696deae2196b"}
``` python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.14079929999979868
    Method: lmdb, Time usage: 0.005631300000004558
    Method: hdf5, Time usage: 0.06091969999988578
:::
:::

::: {.cell .markdown id="DyybUyiLeUqF"}
Fungsi `store_many_disk` digunakan untuk menyimpan array gambar dan
labelnya ke dalam disk. Setiap gambar disimpan dalam format .png dan
labelnya disimpan dalam file .csv terpisah.

Fungsi `store_many_lmdb` digunakan untuk menyimpan array gambar dan
labelnya ke dalam basis data LMDB. Setiap gambar dan label disimpan
dalam satu transaksi di dalam basis data tersebut.

Fungsi `store_many_hdf5` digunakan untuk menyimpan array gambar dan
labelnya ke dalam file HDF5. Semua gambar disimpan dalam satu dataset
bernama \"images\" dan semua label disimpan dalam satu dataset bernama
\"meta\".

Ketiga fungsi ini menerima dua argumen: array gambar dengan dimensi (N,
32, 32, 3) dan array label dengan dimensi (N, 1), di mana N adalah
jumlah gambar yang akan disimpan.
:::

::: {.cell .code id="8SgE-crxeUqF"}
``` python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
:::

::: {.cell .markdown id="RMfHU8ACeUqH"}
Hasil output dibawah menunjukkan bahwa setelah menggandakan jumlah
gambar (images) dan label (labels) dari sebelumnya, sekarang terdapat
100.000 gambar dalam bentuk array dengan dimensi (100000, 32, 32, 3) dan
100.000 label dalam bentuk array dengan dimensi (100000,). Hal ini
dibuktikan oleh hasil print dari `np.shape(images)` yang menunjukkan
dimensi (100000, 32, 32, 3) dan `np.shape(labels)` yang menunjukkan
dimensi (100000,). Dengan kata lain, jumlah gambar dan label telah
berhasil ditingkatkan menjadi 100.000 sesuai dengan yang diinginkan.
:::

::: {.cell .code id="cVavbTZueUqH" outputId="5b423848-4cfc-4fef-aa14-18b9c27e6eed"}
``` python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

::: {.output .stream .stdout}
    (100000, 32, 32, 3)
    (100000,)
:::
:::

::: {.cell .markdown id="oixokR3UeUqI"}
Hasil output dibawah menunjukkan waktu yang dibutuhkan oleh setiap
metode penyimpanan (`disk`, `lmdb`, `hdf5`) untuk menyimpan sejumlah
gambar dan label berdasarkan nilai cutoff yang telah ditentukan
sebelumnya (10, 100, 1000, 10000, 100000).

Pertama, pada nilai cutoff 10, waktu yang dibutuhkan untuk metode `disk`
sekitar 0.043 detik, `lmdb` sekitar 0.013 detik, dan `hdf5` sekitar
0.054 detik.

Kedua, ketika nilai cutoff naik menjadi 100, waktu untuk metode `disk`
meningkat menjadi sekitar 0.167 detik, sedangkan `lmdb` menjadi sekitar
0.005 detik, dan `hdf5` menjadi sekitar 0.002 detik.

Ketiga, saat nilai cutoff terus bertambah hingga mencapai 100000, waktu
eksekusi juga meningkat secara signifikan. Metode `disk` membutuhkan
waktu sekitar 12.147 detik, `lmdb` sekitar 0.297 detik, dan `hdf5`
sekitar 0.026 detik.

Dari hasil ini, dapat disimpulkan bahwa performa relatif dari
masing-masing metode berbeda tergantung pada jumlah data yang disimpan.
Metode `lmdb` cenderung lebih cepat, terutama saat jumlah data yang
disimpan semakin besar. Sementara itu, `disk` membutuhkan waktu lebih
lama karena operasi I/O pada disk, dan `hdf5` menunjukkan waktu eksekusi
yang stabil tergantung pada jumlah data yang disimpan.
:::

::: {.cell .code id="fQ9XzIg7eUqI" outputId="221e9f2d-9066-4907-afdb-ba793c3c2f5d"}
``` python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.043001499999945736
    Method: lmdb, Time usage: 0.013635200000180703
    Method: hdf5, Time usage: 0.054849900000135676
    Method: disk, Time usage: 0.16676769999980934
    Method: lmdb, Time usage: 0.005678900000020803
    Method: hdf5, Time usage: 0.0023858000001837354
    Method: disk, Time usage: 1.6323519000000033
    Method: lmdb, Time usage: 0.03800269999987904
    Method: hdf5, Time usage: 0.005430300000170973
    Method: disk, Time usage: 12.146795200000042
    Method: lmdb, Time usage: 0.29728830000021844
    Method: hdf5, Time usage: 0.025982599999679223
    Method: disk, Time usage: 142.75358489999962
    Method: lmdb, Time usage: 4.296912700000121
    Method: hdf5, Time usage: 0.46554439999999886
:::
:::

::: {.cell .code id="9U-5HAg3eUqJ" outputId="c358ef9d-06a6-4401-d5d8-f2557a0a51ad"}
``` python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

::: {.output .stream .stderr}
    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
:::

::: {.output .display_data}
![](vertopal_d945a1a081df46febfe72bcc778c5353/7162a3c384d7ee9787d100df609eed34319f5bf5.png)
:::

::: {.output .stream .stderr}
    C:\Users\ASUS\AppData\Local\Temp\ipykernel_12376\2568719458.py:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
:::

::: {.output .display_data}
![](vertopal_d945a1a081df46febfe72bcc778c5353/c39ac9c3a10747bb7a215a637405fcb7a1a7e494.png)
:::
:::

::: {.cell .markdown id="eBI_Ibz9iKHm"}
selanjutnya menggunakan fungsi `read_single_disk` digunakan untuk
membaca gambar dan label yang disimpan dalam disk. Gambar dibaca
menggunakan `Image.open` dari modul PIL, kemudian diubah menjadi array
numpy. Labelnya dibaca dari file CSV yang sesuai dengan ID gambar.
Fungsi ini mengembalikan gambar dalam bentuk array dengan dimensi (32,
32, 3) dan labelnya dalam bentuk integer. Dengan demikian, fungsi ini
memungkinkan untuk membaca kembali data gambar dan label yang telah
disimpan dalam format yang telah ditentukan sebelumnya di dalam disk.
:::

::: {.cell .code id="JNzDc9djeUqJ"}
``` python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```
:::

::: {.cell .markdown id="C0FwoFjLihOz"}
Lalu kita menggunakan fungsi `read_single_lmdb` digunakan untuk membaca
gambar dan label yang tersimpan dalam basis data LMDB. Fungsi ini
menerima satu argumen, yaitu `image_id`, yang merupakan ID unik untuk
gambar yang akan dibaca.

Pertama, lingkungan LMDB dibuka dalam mode hanya baca dengan
`lmdb.open`. Kemudian, transaksi baca baru dimulai dengan `env.begin()`.
Key yang digunakan harus diencode seperti yang digunakan saat menyimpan
data.

Selanjutnya, data gambar diambil dari basis data LMDB dengan `txn.get`
dan di-decode menggunakan `pickle.loads`, karena data disimpan sebagai
objek CIFAR_Image.

Setelah itu, gambar direkonstruksi menggunakan `get_image()` dari objek
CIFAR_Image, dan labelnya diambil langsung dari atribut label.

Terakhir, lingkungan LMDB ditutup, dan gambar beserta labelnya
dikembalikan sebagai output dari fungsi. Dengan fungsi ini, Anda dapat
dengan mudah membaca gambar dan label dari basis data LMDB berdasarkan
ID unik gambar yang diberikan.
:::

::: {.cell .code id="lc85P5VseUqK"}
``` python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```
:::

::: {.cell .markdown id="9vKc5-dpjO1Z"}
Fungsi `read_single_hdf5` digunakan untuk membaca sebuah gambar dan
label yang tersimpan dalam file HDF5. Fungsi ini menerima satu argumen,
yaitu `image_id`, yang merupakan ID unik untuk gambar yang akan dibaca.

Pertama, file HDF5 dibuka dalam mode baca dan tulis (r+ mode) dengan
`h5py.File`. Kemudian, gambar dibaca dari dataset \"image\" dalam file
HDF5 dan diubah menjadi array numpy dengan tipe data `uint8` (unsigned
integer 8-bit). Selanjutnya, label dibaca dari dataset \"meta\" dan juga
diubah menjadi integer dengan tipe data `uint8`.

Setelah membaca data gambar dan label, file HDF5 ditutup, dan gambar
beserta labelnya dikembalikan sebagai output dari fungsi.

Dengan fungsi ini, Anda dapat dengan mudah membaca gambar dan label dari
file HDF5 berdasarkan ID unik gambar yang diberikan.
:::

::: {.cell .code id="gMfMOTzpeUqK"}
``` python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```
:::

::: {.cell .markdown id="emBuuQYOjTB0"}
fungsi `_read_single_funcs` membuat sebuah kamus yang berisi tiga
fungsi: `read_single_disk`, `read_single_lmdb`, dan `read_single_hdf5`,
masing-masing terkait dengan metode membaca data dari lokasi penyimpanan
yang berbeda (`disk`, `lmdb`, dan `hdf5`). Hal ini memungkinkan
penggunaan kamus ini untuk memilih metode membaca yang sesuai dengan
kebutuhan aplikasi, dengan cukup memanggil fungsi yang sesuai dengan
kunci yang diinginkan (seperti `'disk'` untuk membaca dari disk,
`'lmdb'` untuk membaca dari LMDB, dan `'hdf5'` untuk membaca dari HDF5).
Dengan cara ini, fleksibilitas dalam memilih cara membaca data dapat
diterapkan dengan mudah dalam program Anda.
:::

::: {.cell .code id="XUeTkqFXeUqL"}
``` python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```
:::

::: {.cell .markdown id="GDyW_G00jkMc"}
Hasil output tersebut menunjukkan waktu yang dibutuhkan (dalam detik)
oleh masing-masing metode (`disk`, `lmdb`, `hdf5`) untuk membaca sebuah
gambar dan label dari lokasi penyimpanan yang berbeda.

Dari hasil tersebut, dapat disimpulkan bahwa metode `hdf5` adalah yang
paling cepat dalam hal waktu membaca data, diikuti oleh metode `lmdb`,
dan metode `disk` merupakan yang memakan waktu paling lama di antara
ketiganya. Informasi ini berguna untuk mengevaluasi performa relatif
dari berbagai metode membaca data dan memilih yang paling sesuai
berdasarkan kebutuhan aplikasi.
:::

::: {.cell .code id="RJ3FHY2BeUqL" outputId="205651f9-1f29-4998-ead6-c593fe8969d0"}
``` python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

::: {.output .stream .stdout}
    Method: disk, Time usage: 0.03221690000009403
    Method: lmdb, Time usage: 0.029903999999987718
    Method: hdf5, Time usage: 0.020119400000112364
:::
:::

::: {.cell .markdown id="2RL0tA1Qjp-K"}
Kode dibawah tersebut mendefinisikan tiga fungsi: `read_many_disk`,
`read_many_lmdb`, dan `read_many_hdf5`, untuk membaca sejumlah gambar
dan label dari berbagai lokasi penyimpanan (disk, LMDB, HDF5).

-   `read_many_disk` membaca gambar dan label dari disk dengan membuka
    file .png untuk setiap gambar dan file .csv untuk labelnya,
    menggunakan modul PIL untuk membaca gambar.
-   `read_many_lmdb` membaca gambar dan label dari basis data LMDB
    dengan membuka transaksi baca menggunakan modul lmdb, kemudian
    mengambil data gambar dan label dari setiap kunci yang sesuai dalam
    basis data.
-   `read_many_hdf5` membaca gambar dan label dari file HDF5 dengan
    membuka file dan membaca dataset \"images\" dan \"meta\" dari file
    tersebut.

Kamus `_read_many_funcs` mengelompokkan ketiga fungsi berdasarkan lokasi
penyimpanan yang berbeda (disk, LMDB, HDF5).

Kode ini memungkinkan untuk membaca sejumlah gambar dan label dari
berbagai lokasi penyimpanan dengan mudah dan fleksibel, tergantung pada
kebutuhan aplikasi.
:::

::: {.cell .code id="tdNNnpsYeUqM"}
``` python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
:::

::: {.cell .markdown id="PLhcC749kLy4"}
Kode dibawh tersebut mengukur waktu yang dibutuhkan untuk membaca
sejumlah gambar dari berbagai metode penyimpanan (disk, LMDB, HDF5)
menggunakan `timeit`. Hasil pengukuran waktu disimpan dalam kamus
`read_many_timings`.

Pada setiap iterasi, kode melakukan pengukuran waktu untuk membaca
sejumlah gambar (`num_images`) berdasarkan metode penyimpanan yang
ditentukan dalam variabel `method`. Pengukuran waktu dilakukan sekali
saja (number=1) untuk setiap metode.

Hasil pengukuran waktu kemudian disimpan dalam kamus `read_many_timings`
untuk masing-masing metode penyimpanan.

Selain itu, kode mencetak informasi tentang metode penyimpanan, jumlah
gambar yang dibaca, dan waktu yang dibutuhkan untuk pembacaan tersebut.

Kode ini memberikan informasi yang berguna untuk mengevaluasi performa
relatif dari berbagai metode pembacaan data tergantung pada jumlah
gambar yang dibaca (`cutoff`) dari setiap metode penyimpanan.
:::

::: {.cell .code id="4Z_pJlMmeUqO" outputId="1446fd32-6c8a-401e-b610-33d21f23df6e"}
``` python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

::: {.output .error ename="IndexError" evalue="list index out of range"}
    ---------------------------------------------------------------------------
    IndexError                                Traceback (most recent call last)
    Cell In [47], line 7
          5 for cutoff in cutoffs:
          6     for method in ("disk", "lmdb", "hdf5"):
    ----> 7         t = timeit(
          8             "_read_many_funcs[method](num_images)",
          9             setup="num_images=cutoff",
         10             number=1,
         11             globals=globals(),
         12         )
         13         read_many_timings[method].append(t)
         15         # Print out the method, cutoff, and elapsed time

    File c:\Users\ASUS\AppData\Local\Programs\Python\Python39\lib\timeit.py:233, in timeit(stmt, setup, timer, number, globals)
        230 def timeit(stmt="pass", setup="pass", timer=default_timer,
        231            number=default_number, globals=None):
        232     """Convenience function to create Timer object and call timeit method."""
    --> 233     return Timer(stmt, setup, timer, globals).timeit(number)

    File c:\Users\ASUS\AppData\Local\Programs\Python\Python39\lib\timeit.py:177, in Timer.timeit(self, number)
        175 gc.disable()
        176 try:
    --> 177     timing = self.inner(it, self.timer)
        178 finally:
        179     if gcold:

    File <timeit-src>:6, in inner(_it, _timer)

    Cell In [42], line 23, in read_many_disk(num_images)
         19     reader = csv.reader(
         20         csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
         21     )
         22     for row in reader:
    ---> 23         labels.append(int(row[0]))
         24 return images, labels

    IndexError: list index out of range
:::
:::
